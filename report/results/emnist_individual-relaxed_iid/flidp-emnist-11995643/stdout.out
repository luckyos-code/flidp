START
Command: python3 src/main.py --save-dir /home/sc.uni-leipzig.de/ll95wyqa/projects/flidp/results/all-2025-01-22_18:03:55/emnist_individual-relaxed_iid_2025-01-22_19:43:35 --dataset emnist --model simple-cnn --budgets 1.0 2.0 3.0 --ratios 0.34 0.43 0.23 --rounds 420 --clients-per-round 30 --local-epochs 15 --batch-size 128 --client-lr 0.0005 --server-lr 1.0 --make-iid
dp level was set to idp.
Starting to create iid dataset
Finished creating iid dataset
Round 0: OrderedDict([('sparse_categorical_accuracy', 0.10072982), ('loss', 2.3129532), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.1, 'sum_stddev': 0.08731473}
Round 1: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.1105171, 'sum_stddev': 0.09649771}
Round 2: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.12214029, 'sum_stddev': 0.10664646}
Round 3: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.1349859, 'sum_stddev': 0.11786257}
Round 4: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.14918248, 'sum_stddev': 0.13025828}
Round 5: OrderedDict([('sparse_categorical_accuracy', 0.112534285), ('loss', 2.2983346), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.16252457, 'sum_stddev': 0.14190789}
Round 6: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.17904297, 'sum_stddev': 0.15633088}
Round 7: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.19374886, 'sum_stddev': 0.1691713}
Round 8: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.20622216, 'sum_stddev': 0.18006232}
Round 9: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.22108582, 'sum_stddev': 0.19304049}
Round 10: OrderedDict([('sparse_categorical_accuracy', 0.13322884), ('loss', 2.2924552), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2429197, 'sum_stddev': 0.21210468}
Round 11: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.26846778, 'sum_stddev': 0.23441193}
Round 12: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2967028, 'sum_stddev': 0.25906524}
Round 13: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31592873, 'sum_stddev': 0.27585232}
Round 14: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33919927, 'sum_stddev': 0.29617092}
Round 15: OrderedDict([('sparse_categorical_accuracy', 0.25031838), ('loss', 2.2463548), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32865915, 'sum_stddev': 0.28696784}
Round 16: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34525397, 'sum_stddev': 0.30145758}
Round 17: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3434284, 'sum_stddev': 0.29986358}
Round 18: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3539833, 'sum_stddev': 0.3090796}
Round 19: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35580662, 'sum_stddev': 0.3106716}
Round 20: OrderedDict([('sparse_categorical_accuracy', 0.3252351), ('loss', 2.1171272), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3347575, 'sum_stddev': 0.29229262}
Round 21: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30801514, 'sum_stddev': 0.2689426}
Round 22: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33099246, 'sum_stddev': 0.2890052}
Round 23: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33645564, 'sum_stddev': 0.29377535}
Round 24: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32415757, 'sum_stddev': 0.2830373}
Round 25: OrderedDict([('sparse_categorical_accuracy', 0.458317), ('loss', 1.827731), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.29953888, 'sum_stddev': 0.26154158}
Round 26: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32402015, 'sum_stddev': 0.28291732}
Round 27: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.29582843, 'sum_stddev': 0.2583018}
Round 28: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.29857367, 'sum_stddev': 0.2606988}
Round 29: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30615038, 'sum_stddev': 0.26731437}
Round 30: OrderedDict([('sparse_categorical_accuracy', 0.48606485), ('loss', 1.572005), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2891737, 'sum_stddev': 0.25249124}
Round 31: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.29815835, 'sum_stddev': 0.26033616}
Round 32: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31349576, 'sum_stddev': 0.27372798}
Round 33: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31050166, 'sum_stddev': 0.2711137}
Round 34: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3204359, 'sum_stddev': 0.27978775}
Round 35: OrderedDict([('sparse_categorical_accuracy', 0.54758525), ('loss', 1.3880502), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30344027, 'sum_stddev': 0.26494807}
Round 36: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.29530185, 'sum_stddev': 0.25784203}
Round 37: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30640325, 'sum_stddev': 0.26753518}
Round 38: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.28446713, 'sum_stddev': 0.2483817}
Round 39: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2942069, 'sum_stddev': 0.25688595}
Round 40: OrderedDict([('sparse_categorical_accuracy', 0.63009405), ('loss', 1.1580156), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30210525, 'sum_stddev': 0.26378238}
Round 41: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30893177, 'sum_stddev': 0.26974294}
Round 42: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3070237, 'sum_stddev': 0.26807693}
Round 43: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31192386, 'sum_stddev': 0.27235547}
Round 44: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.29312518, 'sum_stddev': 0.25594145}
Round 45: OrderedDict([('sparse_categorical_accuracy', 0.7007984), ('loss', 1.0449413), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3183805, 'sum_stddev': 0.27799308}
Round 46: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3192527, 'sum_stddev': 0.27875462}
Round 47: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.315889, 'sum_stddev': 0.27581763}
Round 48: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2961717, 'sum_stddev': 0.25860152}
Round 49: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32671288, 'sum_stddev': 0.28526846}
Round 50: OrderedDict([('sparse_categorical_accuracy', 0.734326), ('loss', 0.92782706), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30667904, 'sum_stddev': 0.26777598}
Round 51: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3238707, 'sum_stddev': 0.28278682}
Round 52: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30260986, 'sum_stddev': 0.26422298}
Round 53: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30571604, 'sum_stddev': 0.26693514}
Round 54: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32688007, 'sum_stddev': 0.28541446}
Round 55: OrderedDict([('sparse_categorical_accuracy', 0.7807357), ('loss', 0.79503113), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31422383, 'sum_stddev': 0.2743637}
Round 56: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31594154, 'sum_stddev': 0.2758635}
Round 57: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.319494, 'sum_stddev': 0.27896532}
Round 58: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.311849, 'sum_stddev': 0.2722901}
Round 59: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3098613, 'sum_stddev': 0.27055457}
Round 60: OrderedDict([('sparse_categorical_accuracy', 0.8138715), ('loss', 0.6867104), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31116208, 'sum_stddev': 0.27169034}
Round 61: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3163241, 'sum_stddev': 0.27619755}
Round 62: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2862219, 'sum_stddev': 0.24991387}
Round 63: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30615106, 'sum_stddev': 0.26731497}
Round 64: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30989453, 'sum_stddev': 0.27058357}
Round 65: OrderedDict([('sparse_categorical_accuracy', 0.8460276), ('loss', 0.58639884), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31773078, 'sum_stddev': 0.27742577}
Round 66: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.325116, 'sum_stddev': 0.28387415}
Round 67: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31211334, 'sum_stddev': 0.27252093}
Round 68: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31386247, 'sum_stddev': 0.27404818}
Round 69: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30714414, 'sum_stddev': 0.26818207}
Round 70: OrderedDict([('sparse_categorical_accuracy', 0.850289), ('loss', 0.533972), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.28213128, 'sum_stddev': 0.24634217}
Round 71: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2944741, 'sum_stddev': 0.25711927}
Round 72: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32446635, 'sum_stddev': 0.28330693}
Round 73: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31490195, 'sum_stddev': 0.27495578}
Round 74: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.30994615, 'sum_stddev': 0.27062866}
Round 75: OrderedDict([('sparse_categorical_accuracy', 0.87534285), ('loss', 0.45706698), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32285407, 'sum_stddev': 0.28189915}
Round 76: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33244637, 'sum_stddev': 0.29027465}
Round 77: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32711098, 'sum_stddev': 0.28561607}
Round 78: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33870125, 'sum_stddev': 0.29573607}
Round 79: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3345961, 'sum_stddev': 0.2921517}
Round 80: OrderedDict([('sparse_categorical_accuracy', 0.8793838), ('loss', 0.44573328), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32362217, 'sum_stddev': 0.28256983}
Round 81: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2987059, 'sum_stddev': 0.26081425}
Round 82: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.2957322, 'sum_stddev': 0.25821778}
Round 83: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31437632, 'sum_stddev': 0.27449685}
Round 84: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32938945, 'sum_stddev': 0.28760552}
Round 85: OrderedDict([('sparse_categorical_accuracy', 0.8951802), ('loss', 0.37883994), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31730732, 'sum_stddev': 0.27705604}
Round 86: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31534687, 'sum_stddev': 0.27534428}
Round 87: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34339947, 'sum_stddev': 0.2998383}
Round 88: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.31072068, 'sum_stddev': 0.27130494}
Round 89: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3236345, 'sum_stddev': 0.28258058}
Round 90: OrderedDict([('sparse_categorical_accuracy', 0.9078174), ('loss', 0.33075476), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33270758, 'sum_stddev': 0.29050273}
Round 91: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3365624, 'sum_stddev': 0.29386854}
Round 92: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3235884, 'sum_stddev': 0.28254035}
Round 93: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32462618, 'sum_stddev': 0.28344646}
Round 94: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34126076, 'sum_stddev': 0.29797092}
Round 95: OrderedDict([('sparse_categorical_accuracy', 0.91141754), ('loss', 0.31563842), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3292842, 'sum_stddev': 0.2875136}
Round 96: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35229635, 'sum_stddev': 0.3076066}
Round 97: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33337513, 'sum_stddev': 0.2910856}
Round 98: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33095422, 'sum_stddev': 0.28897178}
Round 99: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3411309, 'sum_stddev': 0.29785755}
Round 100: OrderedDict([('sparse_categorical_accuracy', 0.9177116), ('loss', 0.29496747), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34116426, 'sum_stddev': 0.29788667}
Round 101: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3458678, 'sum_stddev': 0.30199355}
Round 102: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34574497, 'sum_stddev': 0.3018863}
Round 103: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34971312, 'sum_stddev': 0.30535108}
Round 104: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33193967, 'sum_stddev': 0.28983223}
Round 105: OrderedDict([('sparse_categorical_accuracy', 0.90923786), ('loss', 0.30109224), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34295648, 'sum_stddev': 0.29945153}
Round 106: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33531252, 'sum_stddev': 0.2927772}
Round 107: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3245877, 'sum_stddev': 0.28341287}
Round 108: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35219702, 'sum_stddev': 0.30751988}
Round 109: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3488972, 'sum_stddev': 0.30463865}
Round 110: OrderedDict([('sparse_categorical_accuracy', 0.90918887), ('loss', 0.30719715), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33889377, 'sum_stddev': 0.2959042}
Round 111: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32465035, 'sum_stddev': 0.2834676}
Round 112: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3133794, 'sum_stddev': 0.2736264}
Round 113: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3053283, 'sum_stddev': 0.2665966}
Round 114: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33412322, 'sum_stddev': 0.2917388}
Round 115: OrderedDict([('sparse_categorical_accuracy', 0.92363834), ('loss', 0.26731032), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.32698587, 'sum_stddev': 0.2855068}
Round 116: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3452095, 'sum_stddev': 0.30141875}
Round 117: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34842613, 'sum_stddev': 0.30422735}
Round 118: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33360687, 'sum_stddev': 0.29128793}
Round 119: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33654243, 'sum_stddev': 0.2938511}
Round 120: OrderedDict([('sparse_categorical_accuracy', 0.93235695), ('loss', 0.23474967), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33451137, 'sum_stddev': 0.2920777}
Round 121: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34644556, 'sum_stddev': 0.302498}
Round 122: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3500461, 'sum_stddev': 0.3056418}
Round 123: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35402167, 'sum_stddev': 0.30911306}
Round 124: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35978395, 'sum_stddev': 0.31414437}
Round 125: OrderedDict([('sparse_categorical_accuracy', 0.9325774), ('loss', 0.23042543), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36608177, 'sum_stddev': 0.31964332}
Round 126: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33527443, 'sum_stddev': 0.29274395}
Round 127: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36920393, 'sum_stddev': 0.32236943}
Round 128: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35758483, 'sum_stddev': 0.31222424}
Round 129: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33253452, 'sum_stddev': 0.29035163}
Round 130: OrderedDict([('sparse_categorical_accuracy', 0.9060786), ('loss', 0.31341243), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.33315432, 'sum_stddev': 0.2908928}
Round 131: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3270516, 'sum_stddev': 0.28556424}
Round 132: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3303469, 'sum_stddev': 0.2884415}
Round 133: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36133227, 'sum_stddev': 0.3154963}
Round 134: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34089917, 'sum_stddev': 0.2976552}
Round 135: OrderedDict([('sparse_categorical_accuracy', 0.93945926), ('loss', 0.20993607), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35365698, 'sum_stddev': 0.30879465}
Round 136: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36164072, 'sum_stddev': 0.31576562}
Round 137: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3686162, 'sum_stddev': 0.32185623}
Round 138: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36010274, 'sum_stddev': 0.31442273}
Round 139: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36373854, 'sum_stddev': 0.31759733}
Round 140: OrderedDict([('sparse_categorical_accuracy', 0.9349285), ('loss', 0.22381008), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36482966, 'sum_stddev': 0.31855002}
Round 141: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3813591, 'sum_stddev': 0.33298266}
Round 142: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38294065, 'sum_stddev': 0.3343636}
Round 143: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3684133, 'sum_stddev': 0.3216791}
Round 144: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37379262, 'sum_stddev': 0.32637602}
Round 145: OrderedDict([('sparse_categorical_accuracy', 0.9289038), ('loss', 0.23914777), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35181516, 'sum_stddev': 0.30718645}
Round 146: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3433864, 'sum_stddev': 0.29982692}
Round 147: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36954412, 'sum_stddev': 0.32266647}
Round 148: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37569416, 'sum_stddev': 0.32803634}
Round 149: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36501557, 'sum_stddev': 0.31871235}
Round 150: OrderedDict([('sparse_categorical_accuracy', 0.9461207), ('loss', 0.1875182), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36629876, 'sum_stddev': 0.31983277}
Round 151: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35929203, 'sum_stddev': 0.31371486}
Round 152: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37256435, 'sum_stddev': 0.32530355}
Round 153: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36547858, 'sum_stddev': 0.31911662}
Round 154: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37571037, 'sum_stddev': 0.3280505}
Round 155: OrderedDict([('sparse_categorical_accuracy', 0.9429614), ('loss', 0.19715458), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36818704, 'sum_stddev': 0.32148153}
Round 156: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3632844, 'sum_stddev': 0.3172008}
Round 157: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35638028, 'sum_stddev': 0.3111725}
Round 158: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3765576, 'sum_stddev': 0.32879025}
Round 159: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35900965, 'sum_stddev': 0.3134683}
Round 160: OrderedDict([('sparse_categorical_accuracy', 0.9281446), ('loss', 0.24655427), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37492037, 'sum_stddev': 0.32736072}
Round 161: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3500945, 'sum_stddev': 0.30568406}
Round 162: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35855395, 'sum_stddev': 0.31307042}
Round 163: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36956403, 'sum_stddev': 0.32268384}
Round 164: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37077492, 'sum_stddev': 0.32374114}
Round 165: OrderedDict([('sparse_categorical_accuracy', 0.94124705), ('loss', 0.19134054), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3684745, 'sum_stddev': 0.32173252}
Round 166: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35695457, 'sum_stddev': 0.31167394}
Round 167: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37366912, 'sum_stddev': 0.3262682}
Round 168: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37575057, 'sum_stddev': 0.3280856}
Round 169: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36636207, 'sum_stddev': 0.31988806}
Round 170: OrderedDict([('sparse_categorical_accuracy', 0.94286346), ('loss', 0.18678418), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3555779, 'sum_stddev': 0.31047186}
Round 171: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3687264, 'sum_stddev': 0.32195246}
Round 172: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.381732, 'sum_stddev': 0.33330825}
Round 173: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36985454, 'sum_stddev': 0.3229375}
Round 174: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37764972, 'sum_stddev': 0.32974383}
Round 175: OrderedDict([('sparse_categorical_accuracy', 0.9366183), ('loss', 0.2129293), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36204222, 'sum_stddev': 0.31611618}
Round 176: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3541227, 'sum_stddev': 0.30920127}
Round 177: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3563184, 'sum_stddev': 0.31111845}
Round 178: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35987496, 'sum_stddev': 0.31422386}
Round 179: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36161077, 'sum_stddev': 0.31573948}
Round 180: OrderedDict([('sparse_categorical_accuracy', 0.9430104), ('loss', 0.19121778), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35691667, 'sum_stddev': 0.31164083}
Round 181: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34127086, 'sum_stddev': 0.29797974}
Round 182: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36759424, 'sum_stddev': 0.32096392}
Round 183: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34932998, 'sum_stddev': 0.30501652}
Round 184: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36393538, 'sum_stddev': 0.3177692}
Round 185: OrderedDict([('sparse_categorical_accuracy', 0.94482267), ('loss', 0.18267167), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36871037, 'sum_stddev': 0.32193846}
Round 186: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3552037, 'sum_stddev': 0.31014514}
Round 187: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3630093, 'sum_stddev': 0.3169606}
Round 188: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35960048, 'sum_stddev': 0.3139842}
Round 189: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36193386, 'sum_stddev': 0.31602156}
Round 190: OrderedDict([('sparse_categorical_accuracy', 0.9430104), ('loss', 0.18596043), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3849073, 'sum_stddev': 0.3360808}
Round 191: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35176554, 'sum_stddev': 0.30714315}
Round 192: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36740866, 'sum_stddev': 0.32080188}
Round 193: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34951314, 'sum_stddev': 0.30517647}
Round 194: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35440594, 'sum_stddev': 0.3094486}
Round 195: OrderedDict([('sparse_categorical_accuracy', 0.95351684), ('loss', 0.15531264), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37681618, 'sum_stddev': 0.32901603}
Round 196: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3684186, 'sum_stddev': 0.3216837}
Round 197: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3820903, 'sum_stddev': 0.3336211}
Round 198: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35930553, 'sum_stddev': 0.31372666}
Round 199: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37236384, 'sum_stddev': 0.3251285}
Round 200: OrderedDict([('sparse_categorical_accuracy', 0.9553047), ('loss', 0.1535261), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36134294, 'sum_stddev': 0.31550562}
Round 201: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3590463, 'sum_stddev': 0.31350031}
Round 202: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35151404, 'sum_stddev': 0.30692354}
Round 203: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36007017, 'sum_stddev': 0.3143943}
Round 204: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3594209, 'sum_stddev': 0.3138274}
Round 205: OrderedDict([('sparse_categorical_accuracy', 0.94154096), ('loss', 0.18395072), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36647698, 'sum_stddev': 0.3199884}
Round 206: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34048054, 'sum_stddev': 0.29728967}
Round 207: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3748827, 'sum_stddev': 0.32732782}
Round 208: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3584352, 'sum_stddev': 0.31296673}
Round 209: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37652484, 'sum_stddev': 0.32876164}
Round 210: OrderedDict([('sparse_categorical_accuracy', 0.9486432), ('loss', 0.16871347), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35903555, 'sum_stddev': 0.31349093}
Round 211: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35888472, 'sum_stddev': 0.31335923}
Round 212: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38167316, 'sum_stddev': 0.3332569}
Round 213: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36559314, 'sum_stddev': 0.31921667}
Round 214: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3719658, 'sum_stddev': 0.32478094}
Round 215: OrderedDict([('sparse_categorical_accuracy', 0.9466595), ('loss', 0.1757647), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36410654, 'sum_stddev': 0.31791863}
Round 216: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37261772, 'sum_stddev': 0.32535017}
Round 217: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38779563, 'sum_stddev': 0.33860272}
Round 218: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37126002, 'sum_stddev': 0.3241647}
Round 219: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36680564, 'sum_stddev': 0.32027537}
Round 220: OrderedDict([('sparse_categorical_accuracy', 0.9507494), ('loss', 0.1610505), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35725334, 'sum_stddev': 0.3119348}
Round 221: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3683084, 'sum_stddev': 0.32158747}
Round 222: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3754707, 'sum_stddev': 0.32784122}
Round 223: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3703376, 'sum_stddev': 0.32335928}
Round 224: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36535686, 'sum_stddev': 0.31901035}
Round 225: OrderedDict([('sparse_categorical_accuracy', 0.94695336), ('loss', 0.17293566), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3659215, 'sum_stddev': 0.31950337}
Round 226: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35604653, 'sum_stddev': 0.31088108}
Round 227: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37964937, 'sum_stddev': 0.33148983}
Round 228: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3690698, 'sum_stddev': 0.3222523}
Round 229: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36626557, 'sum_stddev': 0.3198038}
Round 230: OrderedDict([('sparse_categorical_accuracy', 0.9489616), ('loss', 0.17350326), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37292394, 'sum_stddev': 0.32561752}
Round 231: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38163888, 'sum_stddev': 0.33322698}
Round 232: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3711982, 'sum_stddev': 0.32411072}
Round 233: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37473437, 'sum_stddev': 0.3271983}
Round 234: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37368387, 'sum_stddev': 0.32628107}
Round 235: OrderedDict([('sparse_categorical_accuracy', 0.93816125), ('loss', 0.20250425), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3701475, 'sum_stddev': 0.32319328}
Round 236: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34399423, 'sum_stddev': 0.30035764}
Round 237: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3686254, 'sum_stddev': 0.32186428}
Round 238: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37428418, 'sum_stddev': 0.32680523}
Round 239: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35154685, 'sum_stddev': 0.30695218}
Round 240: OrderedDict([('sparse_categorical_accuracy', 0.9550108), ('loss', 0.15098016), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37528485, 'sum_stddev': 0.32767895}
Round 241: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.373904, 'sum_stddev': 0.32647327}
Round 242: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3544374, 'sum_stddev': 0.30947608}
Round 243: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35126415, 'sum_stddev': 0.30670536}
Round 244: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38098478, 'sum_stddev': 0.33265585}
Round 245: OrderedDict([('sparse_categorical_accuracy', 0.95589244), ('loss', 0.14803107), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3668317, 'sum_stddev': 0.3202981}
Round 246: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36445636, 'sum_stddev': 0.31822407}
Round 247: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36036393, 'sum_stddev': 0.3146508}
Round 248: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35464028, 'sum_stddev': 0.3096532}
Round 249: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36556134, 'sum_stddev': 0.3191889}
Round 250: OrderedDict([('sparse_categorical_accuracy', 0.9533454), ('loss', 0.15612231), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3560356, 'sum_stddev': 0.3108715}
Round 251: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36798275, 'sum_stddev': 0.32130313}
Round 252: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37286124, 'sum_stddev': 0.32556278}
Round 253: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37925035, 'sum_stddev': 0.3311414}
Round 254: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35055932, 'sum_stddev': 0.30608994}
Round 255: OrderedDict([('sparse_categorical_accuracy', 0.95488834), ('loss', 0.15261984), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3725412, 'sum_stddev': 0.32528335}
Round 256: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37780443, 'sum_stddev': 0.32987893}
Round 257: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.34756872, 'sum_stddev': 0.3034787}
Round 258: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3626316, 'sum_stddev': 0.3166308}
Round 259: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.373455, 'sum_stddev': 0.32608122}
Round 260: OrderedDict([('sparse_categorical_accuracy', 0.9573619), ('loss', 0.14688306), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35590136, 'sum_stddev': 0.31075433}
Round 261: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3602792, 'sum_stddev': 0.3145768}
Round 262: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3680276, 'sum_stddev': 0.32134232}
Round 263: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35330573, 'sum_stddev': 0.30848795}
Round 264: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37261146, 'sum_stddev': 0.32534468}
Round 265: OrderedDict([('sparse_categorical_accuracy', 0.9551822), ('loss', 0.1590005), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35423017, 'sum_stddev': 0.30929512}
Round 266: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3541477, 'sum_stddev': 0.30922312}
Round 267: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36469737, 'sum_stddev': 0.31843454}
Round 268: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35257348, 'sum_stddev': 0.3078486}
Round 269: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3634908, 'sum_stddev': 0.317381}
Round 270: OrderedDict([('sparse_categorical_accuracy', 0.9530026), ('loss', 0.15410748), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37017614, 'sum_stddev': 0.3232183}
Round 271: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37683308, 'sum_stddev': 0.32903078}
Round 272: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36884797, 'sum_stddev': 0.32205862}
Round 273: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36789578, 'sum_stddev': 0.32122722}
Round 274: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36044973, 'sum_stddev': 0.31472573}
Round 275: OrderedDict([('sparse_categorical_accuracy', 0.9518025), ('loss', 0.16587675), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3575883, 'sum_stddev': 0.31222725}
Round 276: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3475541, 'sum_stddev': 0.3034659}
Round 277: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3641853, 'sum_stddev': 0.3179874}
Round 278: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3689687, 'sum_stddev': 0.32216403}
Round 279: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37114435, 'sum_stddev': 0.3240637}
Round 280: OrderedDict([('sparse_categorical_accuracy', 0.9555496), ('loss', 0.15092148), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3734237, 'sum_stddev': 0.3260539}
Round 281: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37417427, 'sum_stddev': 0.32670924}
Round 282: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37433633, 'sum_stddev': 0.32685077}
Round 283: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36532167, 'sum_stddev': 0.31897962}
Round 284: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3598885, 'sum_stddev': 0.31423566}
Round 285: OrderedDict([('sparse_categorical_accuracy', 0.954472), ('loss', 0.15591687), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36799368, 'sum_stddev': 0.3213127}
Round 286: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37333643, 'sum_stddev': 0.3259777}
Round 287: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37878004, 'sum_stddev': 0.33073077}
Round 288: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36529645, 'sum_stddev': 0.31895763}
Round 289: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38203177, 'sum_stddev': 0.33357}
Round 290: OrderedDict([('sparse_categorical_accuracy', 0.9552802), ('loss', 0.15440981), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38659996, 'sum_stddev': 0.33755872}
Round 291: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36271748, 'sum_stddev': 0.3167058}
Round 292: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37455016, 'sum_stddev': 0.32703745}
Round 293: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37637934, 'sum_stddev': 0.32863462}
Round 294: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38501003, 'sum_stddev': 0.33617046}
Round 295: OrderedDict([('sparse_categorical_accuracy', 0.94474924), ('loss', 0.17993571), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.39012232, 'sum_stddev': 0.34063426}
Round 296: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36529025, 'sum_stddev': 0.3189522}
Round 297: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35479933, 'sum_stddev': 0.30979207}
Round 298: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37689242, 'sum_stddev': 0.3290826}
Round 299: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36362004, 'sum_stddev': 0.31749386}
Round 300: OrderedDict([('sparse_categorical_accuracy', 0.955672), ('loss', 0.15268078), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36686212, 'sum_stddev': 0.32032466}
Round 301: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36550587, 'sum_stddev': 0.31914046}
Round 302: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38271043, 'sum_stddev': 0.3341626}
Round 303: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37190828, 'sum_stddev': 0.32473072}
Round 304: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3621551, 'sum_stddev': 0.31621477}
Round 305: OrderedDict([('sparse_categorical_accuracy', 0.9586354), ('loss', 0.14582804), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3759009, 'sum_stddev': 0.32821685}
Round 306: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35482234, 'sum_stddev': 0.30981216}
Round 307: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3802517, 'sum_stddev': 0.33201575}
Round 308: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37428313, 'sum_stddev': 0.3268043}
Round 309: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37285283, 'sum_stddev': 0.32555544}
Round 310: OrderedDict([('sparse_categorical_accuracy', 0.9587578), ('loss', 0.14546785), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36623245, 'sum_stddev': 0.3197749}
Round 311: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37307227, 'sum_stddev': 0.32574704}
Round 312: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3637638, 'sum_stddev': 0.31761938}
Round 313: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37942177, 'sum_stddev': 0.3312911}
Round 314: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37683842, 'sum_stddev': 0.32903546}
Round 315: OrderedDict([('sparse_categorical_accuracy', 0.95452094), ('loss', 0.16014682), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36552918, 'sum_stddev': 0.31916082}
Round 316: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36356118, 'sum_stddev': 0.31744248}
Round 317: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36874384, 'sum_stddev': 0.3219677}
Round 318: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37543216, 'sum_stddev': 0.32780758}
Round 319: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37305114, 'sum_stddev': 0.3257286}
Round 320: OrderedDict([('sparse_categorical_accuracy', 0.9589293), ('loss', 0.14403737), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3706746, 'sum_stddev': 0.32365355}
Round 321: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3628659, 'sum_stddev': 0.31683537}
Round 322: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3719412, 'sum_stddev': 0.32475945}
Round 323: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36796778, 'sum_stddev': 0.32129008}
Round 324: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3661531, 'sum_stddev': 0.31970558}
Round 325: OrderedDict([('sparse_categorical_accuracy', 0.9549373), ('loss', 0.15161271), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36116552, 'sum_stddev': 0.3153507}
Round 326: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3653227, 'sum_stddev': 0.31898054}
Round 327: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3552409, 'sum_stddev': 0.31017765}
Round 328: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36156154, 'sum_stddev': 0.31569648}
Round 329: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3754545, 'sum_stddev': 0.32782707}
Round 330: OrderedDict([('sparse_categorical_accuracy', 0.95454544), ('loss', 0.15409946), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3551817, 'sum_stddev': 0.31012595}
Round 331: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35590243, 'sum_stddev': 0.31075525}
Round 332: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36394972, 'sum_stddev': 0.31778172}
Round 333: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36535364, 'sum_stddev': 0.31900755}
Round 334: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36436906, 'sum_stddev': 0.31814787}
Round 335: OrderedDict([('sparse_categorical_accuracy', 0.96027625), ('loss', 0.13769086), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3554074, 'sum_stddev': 0.310323}
Round 336: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3646099, 'sum_stddev': 0.31835815}
Round 337: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3718117, 'sum_stddev': 0.32464638}
Round 338: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36224294, 'sum_stddev': 0.31629145}
Round 339: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36870113, 'sum_stddev': 0.3219304}
Round 340: OrderedDict([('sparse_categorical_accuracy', 0.9607171), ('loss', 0.14108284), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37354288, 'sum_stddev': 0.32615796}
Round 341: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37049365, 'sum_stddev': 0.32349554}
Round 342: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38062888, 'sum_stddev': 0.3323451}
Round 343: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36678958, 'sum_stddev': 0.32026133}
Round 344: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36584517, 'sum_stddev': 0.31943673}
Round 345: OrderedDict([('sparse_categorical_accuracy', 0.96003133), ('loss', 0.13733213), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36938557, 'sum_stddev': 0.322528}
Round 346: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36563677, 'sum_stddev': 0.31925476}
Round 347: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3730635, 'sum_stddev': 0.32573938}
Round 348: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37068886, 'sum_stddev': 0.32366598}
Round 349: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37268505, 'sum_stddev': 0.32540894}
Round 350: OrderedDict([('sparse_categorical_accuracy', 0.95136166), ('loss', 0.16361597), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3659451, 'sum_stddev': 0.319524}
Round 351: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37600407, 'sum_stddev': 0.32830694}
Round 352: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36475155, 'sum_stddev': 0.31848183}
Round 353: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37217793, 'sum_stddev': 0.32496616}
Round 354: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37565756, 'sum_stddev': 0.3280044}
Round 355: OrderedDict([('sparse_categorical_accuracy', 0.9611334), ('loss', 0.13539322), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36353782, 'sum_stddev': 0.31742206}
Round 356: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3716676, 'sum_stddev': 0.32452056}
Round 357: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36038643, 'sum_stddev': 0.31467044}
Round 358: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37061068, 'sum_stddev': 0.32359773}
Round 359: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3779692, 'sum_stddev': 0.33002278}
Round 360: OrderedDict([('sparse_categorical_accuracy', 0.9610355), ('loss', 0.13898575), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.39241815, 'sum_stddev': 0.34263885}
Round 361: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.39106527, 'sum_stddev': 0.34145758}
Round 362: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3803632, 'sum_stddev': 0.3321131}
Round 363: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37561724, 'sum_stddev': 0.3279692}
Round 364: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37671876, 'sum_stddev': 0.32893097}
Round 365: OrderedDict([('sparse_categorical_accuracy', 0.96000683), ('loss', 0.13915233), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36733457, 'sum_stddev': 0.32073718}
Round 366: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37709346, 'sum_stddev': 0.32925814}
Round 367: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38196614, 'sum_stddev': 0.33351272}
Round 368: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.35305122, 'sum_stddev': 0.30826572}
Round 369: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37626866, 'sum_stddev': 0.32853797}
Round 370: OrderedDict([('sparse_categorical_accuracy', 0.9595905), ('loss', 0.145853), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.374366, 'sum_stddev': 0.32687664}
Round 371: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.374711, 'sum_stddev': 0.3271779}
Round 372: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3880985, 'sum_stddev': 0.33886716}
Round 373: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3843283, 'sum_stddev': 0.33557522}
Round 374: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.39069864, 'sum_stddev': 0.34113747}
Round 375: OrderedDict([('sparse_categorical_accuracy', 0.9591007), ('loss', 0.13997222), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37839508, 'sum_stddev': 0.33039466}
Round 376: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3674416, 'sum_stddev': 0.32083064}
Round 377: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38008192, 'sum_stddev': 0.33186752}
Round 378: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36653477, 'sum_stddev': 0.32003886}
Round 379: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37310892, 'sum_stddev': 0.32577905}
Round 380: OrderedDict([('sparse_categorical_accuracy', 0.9599334), ('loss', 0.13974705), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.365948, 'sum_stddev': 0.3195265}
Round 381: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38011572, 'sum_stddev': 0.33189702}
Round 382: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37852156, 'sum_stddev': 0.33050507}
Round 383: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36787957, 'sum_stddev': 0.32121307}
Round 384: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.380156, 'sum_stddev': 0.3319322}
Round 385: OrderedDict([('sparse_categorical_accuracy', 0.95709246), ('loss', 0.15044), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37415838, 'sum_stddev': 0.32669538}
Round 386: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37790933, 'sum_stddev': 0.3299705}
Round 387: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.39050198, 'sum_stddev': 0.34096575}
Round 388: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3714933, 'sum_stddev': 0.3243684}
Round 389: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3749009, 'sum_stddev': 0.32734373}
Round 390: OrderedDict([('sparse_categorical_accuracy', 0.95596594), ('loss', 0.14933091), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37912172, 'sum_stddev': 0.33102912}
Round 391: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37301558, 'sum_stddev': 0.32569754}
Round 392: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38496462, 'sum_stddev': 0.33613083}
Round 393: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38345551, 'sum_stddev': 0.33481315}
Round 394: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3685499, 'sum_stddev': 0.32179835}
Round 395: OrderedDict([('sparse_categorical_accuracy', 0.9575333), ('loss', 0.15642823), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36938503, 'sum_stddev': 0.32252756}
Round 396: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38827267, 'sum_stddev': 0.33901924}
Round 397: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37066036, 'sum_stddev': 0.3236411}
Round 398: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38489392, 'sum_stddev': 0.3360691}
Round 399: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3808561, 'sum_stddev': 0.33254346}
Round 400: OrderedDict([('sparse_categorical_accuracy', 0.9588068), ('loss', 0.14715216), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37131622, 'sum_stddev': 0.32421377}
Round 401: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37299836, 'sum_stddev': 0.32568252}
Round 402: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.366139, 'sum_stddev': 0.31969327}
Round 403: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37327126, 'sum_stddev': 0.3259208}
Round 404: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3768064, 'sum_stddev': 0.3290075}
Round 405: OrderedDict([('sparse_categorical_accuracy', 0.9597864), ('loss', 0.14565694), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36644843, 'sum_stddev': 0.31996346}
Round 406: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38121784, 'sum_stddev': 0.33285934}
Round 407: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.36125386, 'sum_stddev': 0.31542784}
Round 408: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38224992, 'sum_stddev': 0.3337605}
Round 409: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38312852, 'sum_stddev': 0.33452764}
Round 410: OrderedDict([('sparse_categorical_accuracy', 0.9450186), ('loss', 0.18390793), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37166587, 'sum_stddev': 0.32451904}
Round 411: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3805008, 'sum_stddev': 0.33223325}
Round 412: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37433773, 'sum_stddev': 0.326852}
Round 413: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.366394, 'sum_stddev': 0.31991595}
Round 414: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3899938, 'sum_stddev': 0.34052202}
Round 415: OrderedDict([('sparse_categorical_accuracy', 0.95944357), ('loss', 0.1460657), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.38255826, 'sum_stddev': 0.3340297}
Round 416: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.37555578, 'sum_stddev': 0.32791552}
Round 417: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.39344645, 'sum_stddev': 0.3435367}
Round 418: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3895712, 'sum_stddev': 0.34015304}
Round 419: {} {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3730521, 'sum_stddev': 0.32572943}
Round 419: OrderedDict([('sparse_categorical_accuracy', 0.9590517), ('loss', 0.1511107), ('num_examples', 40832), ('num_batches', 319)]) {'noise_multiplier_after_adaptive_clipping': 0.8731473, 'sum_clipping_norm': 0.3790569, 'sum_stddev': 0.33097252}
FINISHED
